{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d1d72f-5583-4a96-8fbf-8336b11c89b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.20.0)\n",
      "Requirement already satisfied: evaluate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.2.1+cu121)\n",
      "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.42.4)\n",
      "Requirement already satisfied: flwr[simulation] in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.9.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.23.5)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: cryptography<43.0.0,>=42.0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (42.0.8)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.60.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (1.64.1)\n",
      "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (0.0.2)\n",
      "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (0.12.1)\n",
      "Requirement already satisfied: protobuf<5.0.0,>=4.25.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (4.25.3)\n",
      "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (3.20.0)\n",
      "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (2.0.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (0.9.4)\n",
      "Requirement already satisfied: ray==2.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (2.10.0)\n",
      "Requirement already satisfied: click>=7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (8.1.7)\n",
      "Requirement already satisfied: jsonschema in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (1.0.8)\n",
      "Requirement already satisfied: aiosignal in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (1.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (1.13.0)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from cryptography<43.0.0,>=42.0.4->flwr[simulation]) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (13.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from cffi>=1.12->cryptography<43.0.0,>=42.0.4->flwr[simulation]) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (2.18.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (0.19.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets evaluate 'flwr[simulation]' torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a25786-6d15-4076-889e-3206812a719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flwr[simulation] in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.9.0)\n",
      "Requirement already satisfied: cryptography<43.0.0,>=42.0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (42.0.8)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.60.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (1.64.1)\n",
      "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (0.0.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (1.26.4)\n",
      "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (0.12.1)\n",
      "Requirement already satisfied: protobuf<5.0.0,>=4.25.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (4.25.3)\n",
      "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (3.20.0)\n",
      "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (2.0.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (0.9.4)\n",
      "Requirement already satisfied: ray==2.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flwr[simulation]) (2.10.0)\n",
      "Requirement already satisfied: click>=7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (8.1.7)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (3.15.4)\n",
      "Requirement already satisfied: jsonschema in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (1.0.8)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (24.1)\n",
      "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (6.0.1)\n",
      "Requirement already satisfied: aiosignal in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (1.4.1)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray==2.10.0->flwr[simulation]) (2.32.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from cryptography<43.0.0,>=42.0.4->flwr[simulation]) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer<0.10.0,>=0.9.0->typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (4.12.2)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (13.7.1)\n",
      "Requirement already satisfied: pycparser in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from cffi>=1.12->cryptography<43.0.0,>=42.0.4->flwr[simulation]) (2.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (2.18.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (0.19.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->ray==2.10.0->flwr[simulation]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->ray==2.10.0->flwr[simulation]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->ray==2.10.0->flwr[simulation]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->ray==2.10.0->flwr[simulation]) (2024.7.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr[simulation]) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install 'flwr[simulation]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d784206f-bf38-4be8-89d0-0b82f0f67c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q trl peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b676f0da-91c2-4679-8c41-5eb16fbea9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.42.4)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.23.5)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9537a81-6c20-4934-92c7-6cd9cf40549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft) (2.2.1+cu121)\n",
      "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft) (4.42.4)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft) (0.32.1)\n",
      "Requirement already satisfied: safetensors in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from peft) (0.23.5)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.0)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.5.82)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759ba05e-9619-43d3-adf3-5d2c040a349c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (2.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.23.5)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0187c7d-35da-4af3-8f38-87bc8d901e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import flwr as fl\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from evaluate import load as load_metric\n",
    "from peft import AdaLoraModel, AdaLoraConfig\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, FalconForSequenceClassification\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AdamW\n",
    "from transformers import logging\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac8f01a9-0ab5-48f1-b909-24e97f9426ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘falcon/’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir falcon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe109796-f60a-4c5d-b014-57537e501360",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.simplefilter('ignore')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "CHECKPOINT = \"albert-base-v2\"\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "NUM_CLIENTS = 2\n",
    "NUM_ROUNDS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29827597-a167-4b25-9fc3-79a323a10d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.simplefilter('ignore')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "NUM_CLIENTS = 2\n",
    "NUM_ROUNDS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09e02bcb-599e-462e-bf0a-2bdc510cec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AdaLoraConfig(\n",
    "peft_type=\"ADALORA\", task_type=\"SEQUENCE_CLASSIFICATION\", r=8, lora_alpha=16, target_modules=['query_key_value','dense'],target_r =4,\n",
    "lora_dropout=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40213133-741b-4617-8f6f-f0cb49507c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Rocketknight1/falcon-rw-1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe81b8cf-9382-4387-a3cf-cb2d890be2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "481e3527-6a85-4684-a1bc-30311ad2062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FalconForSequenceClassification.from_pretrained(\"Rocketknight1/falcon-rw-1b\", num_labels=2, **model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e0c7f73-a4b5-4285-8153-bfe5cd10d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaLoraModel(model, config, \"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382dee72-c585-44b5-a3fc-a9c603403c4e",
   "metadata": {},
   "source": [
    "# Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bf16f47-11e3-4233-a254-6e51f08994f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"stanfordnlp/sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b132572-d341-48ec-8f80-b0ebb8c24856",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    \"train\": ds[\"train\"].shuffle(seed=1000),\n",
    "    \"test\": ds[\"validation\"].shuffle(seed=1000)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6663f70c-cb44-457a-b581-7b9bae8c5ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ds[\"validation\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4a7dbfb-20d8-48d7-a746-89bed9d6b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "128caf30-c394-474a-8ea3-b5c341859ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c38bcf7-1fd8-4bb2-8080-70651552575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"sentence\"], truncation=True,padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f039e5a-5466-465e-a374-a38e5373fe82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3af6fda9304490895c0deb7a55d414f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=column_names,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7878e08c-05f0-45fb-8389-e0faae6892ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 872\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "455bd741-c9cd-460f-aa17-ae1a8b542ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1db412ce-42e7-4149-ac59-a43b22c9b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset[\"train\"] = tokenized_dataset[\"train\"].select(range(25000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "773487fb-3571-407e-be0b-083f0542424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    trainloader = DataLoader(\n",
    "        tokenized_dataset[\"train\"],\n",
    "        shuffle=True,\n",
    "        batch_size=4,\n",
    "        collate_fn = DataCollatorWithPadding(tokenizer = tokenizer)\n",
    "    )\n",
    "\n",
    "    testloader = DataLoader(\n",
    "        tokenized_dataset[\"test\"], batch_size=4,\n",
    "        collate_fn = DataCollatorWithPadding(tokenizer = tokenizer)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1183e5e6-1501-4588-8abe-a5252f7305f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0d68955-14bf-4468-b0c4-d682c780f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "446a802f-cc70-45ae-8184-341190ef6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token_id is None:\n",
    "  tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "if tokenizer.model_max_length > 100_000:\n",
    "  tokenizer.model_max_length = 2_048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41c5f56f-fe59-425b-903d-49f047c0da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='falcon/',\n",
    "    # fp16=True,\n",
    "    # bf16=True,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    gradient_accumulation_steps=128,  # Accumulate gradients and perform parameter updating to conserve memory usage\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    learning_rate=2.0e-05,\n",
    "    # log_level=\"info\",   # print the number of trainable params, info of saving and model when training\n",
    "    logging_steps=1,\n",
    "    logging_strategy=\"steps\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_steps=2,\n",
    "    num_train_epochs=1,  ### donot give max steps if you want config from num_train_epochs\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    report_to=\"tensorboard\",\n",
    "    seed=42,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    label_names=[\"labels\"],\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c2b6360-d3df-46d1-8f3f-791175260633",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    # tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    # packing=True,   # see tokenizer.max_model_length\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    # dataset_text_field=\"sentence\",\n",
    "\n",
    "\n",
    "    # peft_config=peft_config,\n",
    "    # model_init_kwargs=model_kwargs,   # pass if you want to load from trainer\n",
    "    # max_seq_length=tokenizer.model_max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f261a9c-4892-4f6d-8772-989889513362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaLoraModel(\n",
       "  (model): FalconForSequenceClassification(\n",
       "    (transformer): FalconModel(\n",
       "      (word_embeddings): Embedding(50304, 2048)\n",
       "      (h): ModuleList(\n",
       "        (0-23): 24 x FalconDecoderLayer(\n",
       "          (self_attention): FalconAttention(\n",
       "            (query_key_value): adalora.SVDLinear(\n",
       "              (base_layer): FalconLinear(in_features=2048, out_features=6144, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.01, inplace=False)\n",
       "              )\n",
       "              (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x2048 (cuda:0)])\n",
       "              (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 6144x12 (cuda:0)])\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n",
       "              (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n",
       "            )\n",
       "            (dense): adalora.SVDLinear(\n",
       "              (base_layer): FalconLinear(in_features=2048, out_features=2048, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.01, inplace=False)\n",
       "              )\n",
       "              (lora_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x2048 (cuda:0)])\n",
       "              (lora_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 2048x12 (cuda:0)])\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_E): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 12x1 (cuda:0)])\n",
       "              (ranknum): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1 (cuda:0)])\n",
       "            )\n",
       "            (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (mlp): FalconMLP(\n",
       "            (dense_h_to_4h): FalconLinear(in_features=2048, out_features=8192, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (dense_4h_to_h): FalconLinear(in_features=8192, out_features=2048, bias=True)\n",
       "          )\n",
       "          (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (score): Linear(in_features=2048, out_features=2, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74403732-f08e-43e3-9838-90684a6dce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs):\n",
    "    optimizer = AdamW(net.parameters(), lr=5e-5)\n",
    "    net.train()\n",
    "    for _ in range(epochs):\n",
    "        for batch in trainloader:\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            outputs = net(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ad59d90-4d13-4cca-9ce7-aad58de035e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, testloader):\n",
    "    metric = load_metric(\"accuracy\")\n",
    "    loss = 0\n",
    "    net.eval()\n",
    "    for batch in testloader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = net(**batch)\n",
    "        logits = outputs.logits\n",
    "        loss += outputs.loss.item()\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = metric.compute()[\"accuracy\"]\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0408deb-6d3f-42cb-a966-2eb88deb09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSTClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, testloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.net.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        self.net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        print(\"Training Started...\")\n",
    "        train(self.net, self.trainloader, epochs=5)\n",
    "        print(\"Training Finished.\")\n",
    "        return self.get_parameters(config={}), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = test(self.net, self.testloader)\n",
    "        return float(loss), len(self.testloader), {\"accuracy\": float(accuracy), \"loss\": float(loss)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f18c24c0-ac92-4dae-b90c-ebb5aa4739c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(cid):\n",
    "  return SSTClient(model, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3703c550-2e66-486b-8751-fa331c52fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0fd3ff7-3a73-4ef5-930f-f8d3115689f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=2, no round_timeout\n",
      "2024-07-18 09:23:07,633\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 1.0, 'object_store_memory': 19135523635.0, 'memory': 38271047271.0, 'node:10.192.12.37': 1.0, 'GPU': 1.0, 'node:__internal_head__': 1.0, 'accelerator_type:L4': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 73, in _submit_job\n",
      "    out_mssg, updated_context = self.actor_pool.get_client_result(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 399, in get_client_result\n",
      "    return self._fetch_future_result(cid)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 280, in _fetch_future_result\n",
      "    res_cid, out_mssg, updated_context = ray.get(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=119180, ip=10.192.12.37, actor_id=8b7c5fa11fd3ca93953dd04d01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f37e81e2620>)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/client_app.py\", line 98, in __call__\n",
      "    return self._call(message, context)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/client_app.py\", line 81, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py\", line 130, in handle_legacy_message_from_msgtype\n",
      "    fit_res = maybe_call_fit(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/client.py\", line 234, in maybe_call_fit\n",
      "    return client.fit(fit_ins)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/numpy_client.py\", line 238, in _fit\n",
      "    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore\n",
      "  File \"/tmp/ipykernel_118606/2096555735.py\", line 18, in fit\n",
      "  File \"/tmp/ipykernel_118606/2429517079.py\", line 7, in train\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/adalora/model.py\", line 235, in forward\n",
      "    outputs = self.model.forward(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 1394, in forward\n",
      "    transformer_outputs = self.transformer(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 1147, in forward\n",
      "    outputs = block(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 828, in forward\n",
      "    mlp_output = self.mlp(mlp_layernorm_out)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 738, in forward\n",
      "    x = self.dense_4h_to_h(x)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 73, in forward\n",
      "    return hidden_states + self.bias\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 22.17 GiB of which 15.94 MiB is free. Process 1230936 has 5.08 GiB memory in use. Process 1231876 has 17.06 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 25.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=119180, ip=10.192.12.37, actor_id=8b7c5fa11fd3ca93953dd04d01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f37e81e2620>)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 22.17 GiB of which 15.94 MiB is free. Process 1230936 has 5.08 GiB memory in use. Process 1231876 has 17.06 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 25.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=119180, ip=10.192.12.37, actor_id=8b7c5fa11fd3ca93953dd04d01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f37e81e2620>)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/client_app.py\", line 98, in __call__\n",
      "    return self._call(message, context)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/client_app.py\", line 81, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py\", line 130, in handle_legacy_message_from_msgtype\n",
      "    fit_res = maybe_call_fit(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/client.py\", line 234, in maybe_call_fit\n",
      "    return client.fit(fit_ins)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/numpy_client.py\", line 238, in _fit\n",
      "    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore\n",
      "  File \"/tmp/ipykernel_118606/2096555735.py\", line 18, in fit\n",
      "  File \"/tmp/ipykernel_118606/2429517079.py\", line 7, in train\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/adalora/model.py\", line 235, in forward\n",
      "    outputs = self.model.forward(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 1394, in forward\n",
      "    transformer_outputs = self.transformer(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 1147, in forward\n",
      "    outputs = block(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 828, in forward\n",
      "    mlp_output = self.mlp(mlp_layernorm_out)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 738, in forward\n",
      "    x = self.dense_4h_to_h(x)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 73, in forward\n",
      "    return hidden_states + self.bias\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 22.17 GiB of which 15.94 MiB is free. Process 1230936 has 5.08 GiB memory in use. Process 1231876 has 17.06 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 25.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=119180, ip=10.192.12.37, actor_id=8b7c5fa11fd3ca93953dd04d01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f37e81e2620>)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 22.17 GiB of which 15.94 MiB is free. Process 1230936 has 5.08 GiB memory in use. Process 1231876 has 17.06 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 25.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 73, in _submit_job\n",
      "    out_mssg, updated_context = self.actor_pool.get_client_result(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 399, in get_client_result\n",
      "    return self._fetch_future_result(cid)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 280, in _fetch_future_result\n",
      "    res_cid, out_mssg, updated_context = ray.get(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=119180, ip=10.192.12.37, actor_id=8b7c5fa11fd3ca93953dd04d01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f37e81e2620>)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/client_app.py\", line 98, in __call__\n",
      "    return self._call(message, context)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/client_app.py\", line 81, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py\", line 130, in handle_legacy_message_from_msgtype\n",
      "    fit_res = maybe_call_fit(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/client.py\", line 234, in maybe_call_fit\n",
      "    return client.fit(fit_ins)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/numpy_client.py\", line 238, in _fit\n",
      "    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore\n",
      "  File \"/tmp/ipykernel_118606/2096555735.py\", line 18, in fit\n",
      "  File \"/tmp/ipykernel_118606/2429517079.py\", line 7, in train\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/adalora/model.py\", line 235, in forward\n",
      "    outputs = self.model.forward(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 1394, in forward\n",
      "    transformer_outputs = self.transformer(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 1147, in forward\n",
      "    outputs = block(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 796, in forward\n",
      "    attn_outputs = self.self_attention(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 396, in forward\n",
      "    fused_qkv = self.query_key_value(hidden_states)  # [batch_size, seq_length, 3 x hidden_size]\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/adalora/layer.py\", line 187, in forward\n",
      "    result += (dropout(x) @ (lora_A * lora_E).T @ lora_B.T) * scaling / ranknum\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 22.17 GiB of which 45.94 MiB is free. Process 1230936 has 5.08 GiB memory in use. Process 1231876 has 17.03 GiB memory in use. Of the allocated memory 16.67 GiB is allocated by PyTorch, and 152.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=119180, ip=10.192.12.37, actor_id=8b7c5fa11fd3ca93953dd04d01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f37e81e2620>)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 22.17 GiB of which 45.94 MiB is free. Process 1230936 has 5.08 GiB memory in use. Process 1231876 has 17.03 GiB memory in use. Of the allocated memory 16.67 GiB is allocated by PyTorch, and 152.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=119180, ip=10.192.12.37, actor_id=8b7c5fa11fd3ca93953dd04d01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f37e81e2620>)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/client_app.py\", line 98, in __call__\n",
      "    return self._call(message, context)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/client_app.py\", line 81, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py\", line 130, in handle_legacy_message_from_msgtype\n",
      "    fit_res = maybe_call_fit(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/client.py\", line 234, in maybe_call_fit\n",
      "    return client.fit(fit_ins)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/client/numpy_client.py\", line 238, in _fit\n",
      "    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore\n",
      "  File \"/tmp/ipykernel_118606/2096555735.py\", line 18, in fit\n",
      "  File \"/tmp/ipykernel_118606/2429517079.py\", line 7, in train\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/adalora/model.py\", line 235, in forward\n",
      "    outputs = self.model.forward(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 1394, in forward\n",
      "    transformer_outputs = self.transformer(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 1147, in forward\n",
      "    outputs = block(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 796, in forward\n",
      "    attn_outputs = self.self_attention(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/falcon/modeling_falcon.py\", line 396, in forward\n",
      "    fused_qkv = self.query_key_value(hidden_states)  # [batch_size, seq_length, 3 x hidden_size]\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/adalora/layer.py\", line 187, in forward\n",
      "    result += (dropout(x) @ (lora_A * lora_E).T @ lora_B.T) * scaling / ranknum\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 22.17 GiB of which 45.94 MiB is free. Process 1230936 has 5.08 GiB memory in use. Process 1231876 has 17.03 GiB memory in use. Of the allocated memory 16.67 GiB is allocated by PyTorch, and 152.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=119180, ip=10.192.12.37, actor_id=8b7c5fa11fd3ca93953dd04d01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7f37e81e2620>)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 22.17 GiB of which 45.94 MiB is free. Process 1230936 has 5.08 GiB memory in use. Process 1231876 has 17.03 GiB memory in use. Of the allocated memory 16.67 GiB is allocated by PyTorch, and 152.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 2 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def weighted_average(metrics):\n",
    "  accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "  losses = [num_examples * m[\"loss\"] for num_examples, m in metrics]\n",
    "  examples = [num_examples for num_examples, _ in metrics]\n",
    "  return {\"accuracy\": sum(accuracies) / sum(examples), \"loss\": sum(losses) / sum(examples)}\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1,\n",
    "    fraction_evaluate=1,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 1, \"num_gpus\": 1,\n",
    "                     },\n",
    "    ray_init_args={\"log_to_driver\": False, \"num_cpus\": 1, \"num_gpus\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e64a80f5-da38-4758-aa63-a9845d92aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'Falcon_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563bf1af-94ea-4c29-82a2-f042444edf5f",
   "metadata": {},
   "source": [
    "# New_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6812bc-f33b-42a9-a5ef-0e11390de3a1",
   "metadata": {},
   "source": [
    "AlBerta Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5fb91e2-ae80-4556-87cf-821cfd60b2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c163495c434c16a29a144f8bfbfa61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdbf070eb3a425fae62d2dbe121a78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebf699f561d4398a83f8c9e196a658f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef13d62-1f1f-4b2e-8c01-d883bd6d7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    CHECKPOINT, num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d75162d-55f0-4b37-8e51-eb2ac4a3f498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertForSequenceClassification(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "948de1b8-460c-454c-ae6a-5cff6966d77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlbertaConfig = AdaLoraConfig(\n",
    "peft_type=\"ADALORA\", task_type=\"SEQUENCE_CLASSIFICATION\", r=8, lora_alpha=16, target_modules=['query','key','value'],target_r =4,\n",
    "lora_dropout=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0e1c421-7474-4090-99db-eb01c3324c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    trainloader = DataLoader(\n",
    "        tokenized_dataset[\"train\"],\n",
    "        shuffle=True,\n",
    "        batch_size=32,\n",
    "        collate_fn = DataCollatorWithPadding(tokenizer = tokenizer)\n",
    "    )\n",
    "\n",
    "    testloader = DataLoader(\n",
    "        tokenized_dataset[\"test\"], batch_size=32,\n",
    "        collate_fn = DataCollatorWithPadding(tokenizer = tokenizer)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc9a897b-6d10-49bd-900c-0211daa28138",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaLoraModel(model, AlbertaConfig, \"default\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b9c58ae-0594-4d89-9133-75136a16229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs):\n",
    "    optimizer = AdamW(net.parameters(), lr=5e-5)\n",
    "    net.train()\n",
    "    for _ in range(epochs):\n",
    "        for batch in trainloader:\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            outputs = net(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    metric = load_metric(\"accuracy\")\n",
    "    loss = 0\n",
    "    net.eval()\n",
    "    for batch in testloader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = net(**batch)\n",
    "        logits = outputs.logits\n",
    "        loss += outputs.loss.item()\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = metric.compute()[\"accuracy\"]\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acc9c11b-eff6-4309-b82f-c2be3f405577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, testloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.net.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        self.net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        print(\"Training Started...\")\n",
    "        train(self.net, self.trainloader, epochs=5)\n",
    "        print(\"Training Finished.\")\n",
    "        return self.get_parameters(config={}), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = test(self.net, self.testloader)\n",
    "        return float(loss), len(self.testloader), {\"accuracy\": float(accuracy), \"loss\": float(loss)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a43ba89-2a8f-4c29-bee8-22b4a7d0ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(cid):\n",
    "  return IMDBClient(model, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cfeee248-1b77-47cf-9085-53e58557ad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=8, no round_timeout\n",
      "2024-07-17 18:45:04,384\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'object_store_memory': 18994330828.0, 'memory': 37988661659.0, 'GPU': 1.0, 'node:10.192.10.193': 1.0, 'node:__internal_head__': 1.0, 'accelerator_type:L4': 1.0, 'CPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 8 round(s) in 17230.81s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.023641480765211473\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.02160511651170363\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.019594239566577683\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.010389233076381028\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.008950578945970863\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.007895996956445208\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.009031598968858566\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.008141585540265665\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.5286697247706422),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.5344036697247706),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.7522935779816514),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.8899082568807339),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.9059633027522935),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.9128440366972477),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.9025229357798165),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.9071100917431193)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'loss': [(1, 0.023641480765211473),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (2, 0.02160511651170363),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (3, 0.019594239566577683),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (4, 0.010389233076381028),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (5, 0.008950578945970863),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (6, 0.007895996956445208),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (7, 0.009031598968858566),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (8, 0.008141585540265665)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.023641480765211473\n",
       "\tround 2: 0.02160511651170363\n",
       "\tround 3: 0.019594239566577683\n",
       "\tround 4: 0.010389233076381028\n",
       "\tround 5: 0.008950578945970863\n",
       "\tround 6: 0.007895996956445208\n",
       "\tround 7: 0.009031598968858566\n",
       "\tround 8: 0.008141585540265665\n",
       "History (metrics, distributed, evaluate):\n",
       "{'accuracy': [(1, 0.5286697247706422),\n",
       "              (2, 0.5344036697247706),\n",
       "              (3, 0.7522935779816514),\n",
       "              (4, 0.8899082568807339),\n",
       "              (5, 0.9059633027522935),\n",
       "              (6, 0.9128440366972477),\n",
       "              (7, 0.9025229357798165),\n",
       "              (8, 0.9071100917431193)],\n",
       " 'loss': [(1, 0.023641480765211473),\n",
       "          (2, 0.02160511651170363),\n",
       "          (3, 0.019594239566577683),\n",
       "          (4, 0.010389233076381028),\n",
       "          (5, 0.008950578945970863),\n",
       "          (6, 0.007895996956445208),\n",
       "          (7, 0.009031598968858566),\n",
       "          (8, 0.008141585540265665)]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weighted_average(metrics):\n",
    "  accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "  losses = [num_examples * m[\"loss\"] for num_examples, m in metrics]\n",
    "  examples = [num_examples for num_examples, _ in metrics]\n",
    "  return {\"accuracy\": sum(accuracies) / sum(examples), \"loss\": sum(losses) / sum(examples)}\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,\n",
    "    fraction_evaluate=1.0,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 1, \"num_gpus\": 1},\n",
    "    ray_init_args={\"log_to_driver\": False, \"num_cpus\": 1, \"num_gpus\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0147dfec-0395-4eb1-bc8e-258730cf7f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'Alberta_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454b640-8315-425f-9b58-997d808dd87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
